# 架构设计：分层代理系统（Hierarchical Agent System）

**版本**: 2.0
**状态**: 已确认
**日期**: 2025-06-24

## 1. 核心思想：对话式委派模型 (Conversational Delegation Model)

为了提升系统的专业性和能力上限，我们将现有的单一 Agent 模型升级为由一个“大脑”统一协调的、多个“专家”协作的分层代理系统。

其核心思想是：**大脑 (Orchestrator) 负责主持整场对话，它决定在哪个阶段，将对话的控制权（“话筒”）交给哪个专家 Agent。专家在拿到“话筒”后，可以和用户进行多轮对话来澄清需求，直到完成自己的子任务，然后将成果和控制权交还给大脑。**

## 2. Agent 角色定义

### 2.1. Orchestrator Agent (大脑 / 主持人)

-   **职责**:
    1.  **理解与路由**: 作为系统唯一入口，分析用户意图，决定委派给哪个专家。
    2.  **移交控制权**: 暂停自身活动，将对话控制权完全交给指定的专家 Agent。
    3.  **等待与接收**: 等待专家 Agent 主动返回成果摘要。
    4.  **主持与总结**: 接收成果后，根据全局任务目标，决定继续委派给下一个专家，或进行最终总结并回复用户。

### 2.2. Specialist Agent (专家 / 临时主角)

-   **职责**:
    1.  **接收任务**: 从大脑处接收初始任务指令。
    2.  **独立对话**: 拥有独立的对话循环。若信息不足，可直接向用户提问以收集完成任务所需的全部信息。
    3.  **执行工具**: 在信息充足后，调用自身的专业工具（如 API 查询）来完成任务。
    4.  **归还控制权**: 任务完成后，生成结果摘要，并连同对话控制权一起交还给大脑。

## 3. 关键技术实现

### 3.1. 委派机制：Function Calling

我们将采用 **Function Calling** 作为大脑向专家委派任务的机制。

-   **实现**: 大脑的 LLM 会被提供一组“工具”，每个工具对应一个专家 Agent（如 `delegate_to_transportation_agent(...)`）。
-   **流程**: 大脑 LLM 决定调用某个工具后，会生成结构化的 JSON。Go 代码捕获此调用，并执行对应专家 Agent 的 `Execute` 方法。
-   **优势**: 高度结构化、可靠，且与 `langchaingo` 框架无缝集成。

### 3.2. 指令优化：Prompt Engineering

为了让专家能更好地理解任务，大脑将在委派前对指令进行“精炼”和“增强”。

-   **实现**: 通过精心设计大脑的 **System Prompt**，要求它在调用专家工具前，必须结合完整的对话历史和上下文，将用户的原始请求重写为一个清晰、具体的任务描述。
-   **示例**: 用户的模糊请求“订票去北京”，将被大脑优化为具体的指令：“用户希望查询明天从上海出发前往北京的交通票务信息。请与用户确认具体的交通方式和时间偏好，并完成查询。”

## 4. 最终目录结构

```
travel-u/
├── cmd/app/main.go
├── internal/
│   ├── agents/
│   │   ├── base.go
│   │   ├── orchestrator/
│   │   │   └── agent.go
│   │   ├── transportation/
│   │   │   └── agent.go
│   │   └── destination/
│   │       └── agent.go
│   ├── llm/
│   │   └── tools.go
│   └── service/
│       └── mcp.go
├── pkg/
└── memory_bank/
```
