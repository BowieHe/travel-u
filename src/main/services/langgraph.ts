import { BaseMessage, HumanMessage } from '@langchain/core/messages';
import { initializeGraph } from './workflows/main-graph';
import { Command } from '@langchain/langgraph';

/**
 * LangGraph æœåŠ¡ç±»
 * å¤„ç†èŠå¤©æ¶ˆæ¯å¹¶æ‰§è¡Œ AI å·¥ä½œæµ
 */
export class LangGraphService {
    private static instance: LangGraphService | null = null;
    private graph: any = null;
    private isInitialized = false;
    private initializationPromise: Promise<void> | null = null;

    private constructor() {}

    static getInstance(): LangGraphService {
        if (!LangGraphService.instance) {
            LangGraphService.instance = new LangGraphService();
        }
        return LangGraphService.instance;
    }

    async initialize(): Promise<void> {
        if (this.isInitialized) return;
        if (this.initializationPromise) return this.initializationPromise;
        this.initializationPromise = this.doInitialize();
        return this.initializationPromise;
    }

    private async doInitialize(): Promise<void> {
        try {
            console.log('åˆå§‹åŒ– LangGraph...');
            this.graph = await initializeGraph();
            console.log('LangGraph åˆå§‹åŒ–æˆåŠŸ');
            this.isInitialized = true;
        } catch (e) {
            console.error('LangGraph åˆå§‹åŒ–å¤±è´¥:', e);
            throw e;
        }
    }

    isReady(): boolean {
        return this.isInitialized && this.graph !== null;
    }

    /**
     * ç»Ÿä¸€çš„æµå¼å¤„ç†æ–¹æ³•
     * æ”¯æŒæ€è€ƒæ¨¡å‹çš„ additional_kwargs.reasoning_content å¤„ç†
     */
    async *streamMessage(
        message: string,
        sessionId = 'default'
    ): AsyncGenerator<string, void, unknown> {
        if (!this.isInitialized || !this.graph) {
            yield JSON.stringify({ error: 'NOT_INITIALIZED' });
            return;
        }

        const config = { configurable: { thread_id: sessionId } };

        try {
            // æ£€æŸ¥å›¾çš„å½“å‰çŠ¶æ€
            const graphState = await this.graph.getState(config);
            let input: any;

            if (graphState.tasks && graphState.tasks.length > 0 && graphState.tasks[0].interrupts) {
                const interrupts = graphState.tasks[0].interrupts;
                console.log('Current interrupts:', interrupts);
                input = new Command({ resume: message });
            } else {
                console.log('Starting new conversation...');
                input = {
                    messages: [new HumanMessage(message)],
                };
            }

            const stream = await this.graph.stream(input, {
                ...config,
                streamMode: ['messages', 'updates'],
            });

            // çŠ¶æ€æ§åˆ¶
            const emittedInterruptIds = new Set<string>();
            const suppressNodes: string[] = [
                'router',
                'trip_plan_summary',
                'process_response',
                'ask_subgraph',
            ];
            
            // æ€è€ƒå†…å®¹çŠ¶æ€ç®¡ç†
            let hasOutputThinkingHeader = false;
            let hasOutputAnswerHeader = false;

            for await (const item of stream) {
                if (Array.isArray(item)) {
                    const [mode, data] = item.length === 2 ? item : ['messages', item];
                    if (mode === 'messages') {
                        const msgArr = Array.isArray(data) ? data : [data];
                        const msg = msgArr[0] as BaseMessage;
                        const meta = (msgArr[1] as any) || {};
                        const nodeName: string = meta.langgraph_node || meta.name || '';
                        
                        if (suppressNodes.includes(nodeName)) continue;

                        const ctor = (msg as any)?.constructor?.name;
                        if (ctor === 'HumanMessage') continue;
                        
                        // å¤„ç†AIæ¶ˆæ¯å†…å®¹
                        const content: any = (msg as any).content;
                        const additionalKwargs = (msg as any).additional_kwargs || {};
                        const reasoningContent = additionalKwargs.reasoning_content;
                        
                        // è°ƒè¯•æ—¥å¿—
                        if (reasoningContent || content) {
                            console.log('Processing AI message:', {
                                hasReasoningContent: !!reasoningContent,
                                hasContent: !!content,
                                reasoningLength: reasoningContent ? reasoningContent.length : 0,
                                contentLength: content ? content.length : 0
                            });
                        }
                        
                        // å¤„ç†æ€è€ƒå†…å®¹ (reasoning_content)
                        if (reasoningContent && typeof reasoningContent === 'string') {
                            if (!hasOutputThinkingHeader) {
                                yield '## ğŸ¤” æ€è€ƒ\n';
                                hasOutputThinkingHeader = true;
                            }
                            yield reasoningContent;
                        }
                        
                        // å¤„ç†æ­£æ–‡å†…å®¹ (content)
                        if (content && typeof content === 'string') {
                            // å¦‚æœä¹‹å‰è¾“å‡ºäº†æ€è€ƒå†…å®¹ï¼Œéœ€è¦æ·»åŠ å›ç­”header
                            if (hasOutputThinkingHeader && !hasOutputAnswerHeader) {
                                yield '\n\n## ğŸ“ å›ç­”\n';
                                hasOutputAnswerHeader = true;
                            }
                            yield content;
                        }
                        
                    } else if (mode === 'updates') {
                        // å¤„ç† interrupt æ›´æ–°
                        if (data && data.__interrupt__) {
                            const intr = data.__interrupt__[0];
                            const intrId = intr.interrupt_id;
                            if (!emittedInterruptIds.has(intrId)) {
                                emittedInterruptIds.add(intrId);
                            }
                        }
                    }
                }
            }
        } catch (e: any) {
            // æ£€æŸ¥æ˜¯å¦æ˜¯ä¸­æ–­å¼‚å¸¸
            if (e.name === 'NodeInterrupt' || e.message?.includes('interrupt')) {
                console.log('Graph execution interrupted, waiting for user input');
                yield JSON.stringify({ type: 'interrupt', code: 'user_input_needed' });
            } else {
                console.error('æ‰§è¡Œå›¾æ—¶å¼‚å¸¸:', e);
                yield JSON.stringify({ error: 'EXECUTION_ERROR', message: e.message });
            }
        }
    }
}